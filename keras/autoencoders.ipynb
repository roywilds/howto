{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Utility-Functions\" data-toc-modified-id=\"Utility-Functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Utility Functions</a></div><div class=\"lev1 toc-item\"><a href=\"#MNIST\" data-toc-modified-id=\"MNIST-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>MNIST</a></div><div class=\"lev2 toc-item\"><a href=\"#Deep-Autoencoder\" data-toc-modified-id=\"Deep-Autoencoder-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Deep Autoencoder</a></div><div class=\"lev2 toc-item\"><a href=\"#Shallow-Autoencoder\" data-toc-modified-id=\"Shallow-Autoencoder-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Shallow Autoencoder</a></div><div class=\"lev1 toc-item\"><a href=\"#Denoising-Autoencoder\" data-toc-modified-id=\"Denoising-Autoencoder-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Denoising Autoencoder</a></div><div class=\"lev1 toc-item\"><a href=\"#Sparse-Autoencoders\" data-toc-modified-id=\"Sparse-Autoencoders-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sparse Autoencoders</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Author: Roy Wilds\n",
    "Created: 2020-12-12\n",
    "Description: Combining various sources (see credits below) to provide a complete example of using an Autoencoder with Keras (with Tensorflow) that covers the \"gotchas\" that I found challenging.\n",
    "```\n",
    "\n",
    "Credits:\n",
    "- Relies heavily on the great work from https://github.com/ardendertat/Applied-Deep-Learning-with-Keras/blob/master/notebooks/Part%203%20-%20Autoencoders.ipynb \n",
    "- Incorporates material from E2EML Course 312: https://end-to-end-machine-learning.teachable.com/courses/enrolled/612528\n",
    "\n",
    "Layout of this notebook is\n",
    "- Import what's needed and then define some handy functions.\n",
    "- Create our dataset\n",
    "- Learn a simple 5 layer model and then understand what it's doing.\n",
    "- Learn a sparse 3 layer model (just 1 hidden layer). Compare with a non-sparse model of the same dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.datasets import mnist\n",
    "from keras.regularizers import l1\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "Small modifications from original: https://github.com/ardendertat/Applied-Deep-Learning-with-Keras/blob/master/notebooks/Part%203%20-%20Autoencoders.ipynb\n",
    "\n",
    "Keep in mind that these functions rely on having access to some global variables (e.g. `x_test`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autoencoder_outputs(autoencoder, dims, n=5):\n",
    "    decoded_imgs = autoencoder.predict(x_test)\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    for i in range(n):\n",
    "        # plot original image\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(*dims))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Original Images')\n",
    "\n",
    "        # plot reconstruction \n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(*dims))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Reconstructed Images')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, historydf.values.max()))\n",
    "    plt.title('Loss: %.3f' % history.history['loss'][-1])\n",
    "    \n",
    "def plot_compare_histories(history_list, name_list, plot_accuracy=True):\n",
    "    dflist = []\n",
    "    min_epoch = len(history_list[0].epoch)\n",
    "    losses = []\n",
    "    for history in history_list:\n",
    "        h = {key: val for key, val in history.history.items() if not key.startswith('val_')}\n",
    "        dflist.append(pd.DataFrame(h, index=history.epoch))\n",
    "        min_epoch = min(min_epoch, len(history.epoch))\n",
    "        losses.append(h['loss'][-1])\n",
    "\n",
    "    historydf = pd.concat(dflist, axis=1)\n",
    "\n",
    "    metrics = dflist[0].columns\n",
    "    idx = pd.MultiIndex.from_product([name_list, metrics], names=['model', 'metric'])\n",
    "    historydf.columns = idx\n",
    "    \n",
    "    plt.figure(figsize=(6, 8))\n",
    "\n",
    "    ax = plt.subplot(211)\n",
    "    historydf.xs('loss', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "    plt.title(\"Training Loss: \" + ' vs '.join([str(round(x, 3)) for x in losses]))\n",
    "    \n",
    "    if plot_accuracy:\n",
    "        ax = plt.subplot(212)\n",
    "        historydf.xs('acc', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "    \n",
    "    plt.xlim(0, min_epoch-1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Sticking with Arden Dertat's article/code, we'll use the MNIST dataset. https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize!\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "# Reshape so that we have a flat vector for each image\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Autoencoder Structure\n",
    "Define our layer sizes. We have:\n",
    "- Input Layer (layer size is determined by image size)\n",
    "- Encoder Hidden Layer (first hidden layer)\n",
    "- Code layer (our middle layer that will be our \"coded\" representation)\n",
    "- Decoder Hidden Layer (same size as Encoder Hidden Layer)\n",
    "- Output Layer (same size as Input Layer)\n",
    "\n",
    "To start, we're just going to train a vanilla autoencoder. This will learn whatever weights the optimizer happens to settle on after training. \n",
    "\n",
    "In later sections we'll see how to constrain the weights learned based on useful properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784  # 784 = 28*28 (images are 28 by 28 pixels... grayscaled)\n",
    "hidden_size = 128  # We're using  single hidden layer. \n",
    "code_size = 32  # Dimension of our \"coded\" or compressed representation. 32 is much less than the 784 input dimension.\n",
    "\n",
    "# This is how you construct your network in Keras. Chaining the layers by referencing the previous layer.\n",
    "# Really damn cool and simple.\n",
    "input_img = Input(shape=(input_size,))\n",
    "hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "code = Dense(code_size, activation='relu')(hidden_1)\n",
    "hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "# With our layers defined, then the full ANN model is created by specifying the input and output.\n",
    "autoencoder = Model(input_img, output_img)\n",
    "# Define our optimizer and loss function\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "# And train it. \n",
    "# Automatically uses multiple cores (if you have them). Can also use GPUs if you've got them.\n",
    "autoencoder.fit(x_train, x_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "## Accuracy\n",
    "With our model trained, let's compare some inputs to outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the learned model, the image size (must be same used for the input layer size reshaped to be 2-d), \n",
    "# and the number of images to show (default is 5)\n",
    "# Note that the held out test set x_test is used.\n",
    "plot_autoencoder_outputs(autoencoder, (28, 28), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good considering that the inputs are 784 dimensional vectors and we're compressing them down to a 32 dimensional representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Construction\n",
    "This may be ill-named, but what we can do with our learned model is see what the learned weights are doing to the input vectors at the first layer. \n",
    "\n",
    "This can give us some insight into what the learned network is doing to the input images to \"best\" represent them so that the 32-dimensional code layer is able to efficiently reconstruct the outputs accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we focus on the weights connecting the first layer (input image that's flattened from 28x28 to 784) to the next layer (128 nodes), then we have a 784 by 128 matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = autoencoder.get_weights()[0].T\n",
    "\n",
    "n = 10  # Just plotting the first 10 hidden layer nodes.\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(weights[i+0].reshape(28, 28))  # Get the weights going to hidden layer node i. Reshape.\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sparse Autoencoders\n",
    "Okay. This is really cool. \n",
    "\n",
    "We're going to use a shallower network. Just\n",
    "- Input Layer\n",
    "- Code Layer\n",
    "- Output Layer\n",
    "\n",
    "And, we're going to compare a vanilla learned network (just like we did above, but with less layers) against a network learned with a penalty for having non-zero weights. \n",
    "\n",
    "This is an example of using a regularizer. With Keras, this is super easy. Just add an additional argument to the specification of the Code Layer:\n",
    "```\n",
    "code = Dense(code_size, activation='relu', activity_regularizer=l1(10e-6))(input_img)\n",
    "```\n",
    "The `l1(10e-6)` isn't terribly clear to me. But, according to https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798 it's usually a value between `0.001` and `0.000001`. I suspect choosing this is like choosing your learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "code_size = 32\n",
    "\n",
    "input_img = Input(shape=(input_size,))\n",
    "code = Dense(code_size, activation='relu')(input_img)\n",
    "output_img = Dense(input_size, activation='sigmoid')(code)\n",
    "\n",
    "autoencoder_standard = Model(input_img, output_img)\n",
    "autoencoder_standard.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "history_standard = autoencoder_standard.fit(x_train, x_train, epochs=20)\n",
    "\n",
    "encoded_standard = Model(input_img, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "code_size = 32\n",
    "\n",
    "input_img = Input(shape=(input_size,))\n",
    "code = Dense(code_size, activation='relu', activity_regularizer=l1(10e-6))(input_img)  # Note the regularizer\n",
    "output_img = Dense(input_size, activation='sigmoid')(code)\n",
    "\n",
    "autoencoder_regularized = Model(input_img, output_img)\n",
    "autoencoder_regularized.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "history_regularized = autoencoder_regularized.fit(x_train, x_train, epochs=20)\n",
    "\n",
    "encoded_regularized = Model(input_img, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regularized model reconstruction\n",
    "plot_autoencoder_outputs(autoencoder_regularized, (28, 28), 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really good still! And we can compare the lsos functions of vanilla and regularized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the loss functions. Note that since this is an auto-encoder, we only have the loss variable to plot. No accuracy.\n",
    "plot_compare_histories([history_standard, history_regularized], \n",
    "                       ['Standard Autoencoder', 'Regularized Autoencoder'], plot_accuracy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Model Structure\n",
    "How can we understand or verify that the regularized model is indeed more sparse? \n",
    "\n",
    "To start, we can have the models predict the \"coded\" layer on the held out test set `x_test`. This gives a 32-dimensional vector for each image in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte the mean of each 32 dimensional predicted \"code\" across the test set\n",
    "encoded_standard.predict(x_test).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for the regularized model.\n",
    "encoded_regularized.predict(x_test).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not terribly easy to interpret the above with the output truncated. We can take the mean() acrosss the 32 dimensions too, to get a single number that communicates the average value of the 32 dimensional coded representations of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_standard.predict(x_test).mean())\n",
    "print(encoded_regularized.predict(x_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a big difference, but something. \n",
    "\n",
    "Also, each element is `>=0`. I don't entirely understand why there are no negative values. Maybe something to do with the loss function and inputs only being non-negative?\n",
    "\n",
    "Lastly, let's plot the distribution of the predicted values. This is a more meaningful representation of the \"coded\" layer, compared to just reporting the means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scores = encoded_standard.predict(x_test).ravel()  # ravel() flattens the matrix of 1000 by 32\n",
    "regularized_scores = encoded_regularized.predict(x_test).ravel()\n",
    "sns.distplot(standard_scores, hist=False, label='standard model')\n",
    "ax = sns.distplot(regularized_scores, hist=False, label='regularized model')\n",
    "ax.set(xlabel='Coded Vector Value', ylabel='Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can see that the regularized model has a higher density at lower values than the standard/vanilla one. That aligns with our expectations that the regularized model has more values at/near 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Weights\n",
    "Last thing I'd like to do is compare the weights visualization of the standard vs regularized. \n",
    "\n",
    "We've got a 32 node coded layer so going to plot them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = encoded_standard.get_weights()[0].T\n",
    "\n",
    "n = 32  # Just plotting the first 10 hidden layer nodes.\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(4, n/4, i + 1)\n",
    "    plt.imshow(weights[i+0].reshape(28, 28))  # Get the weights going to hidden layer node i. Reshape.\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = encoded_regularized.get_weights()[0].T\n",
    "\n",
    "n = 32  # Just plotting the first 10 hidden layer nodes.\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(4, n/4, i + 1)\n",
    "    plt.imshow(weights[i+0].reshape(28, 28))  # Get the weights going to hidden layer node i. Reshape.\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing really stands out. Some of them seem to indicate structure, like a ring, but both regularized and standard show it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
